{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SYBxVFQwbO0cdOHjwgULJaY7YMWhbEf9",
      "authorship_tag": "ABX9TyMXrLVLCEAH6TLjlHBh4MsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajapatiraghulal/editor_project/blob/app_v1/lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbUExeS9qYq7",
        "outputId": "de7b7fd9-e11b-48a4-abdc-9026ae50f473"
      },
      "source": [
        "!pip install mxnet-cu101mkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet-cu101mkl\n",
            "  Downloading mxnet_cu101mkl-1.6.0.post0-py2.py3-none-manylinux1_x86_64.whl (712.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 712.3 MB 337 bytes/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101mkl) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101mkl) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (2.10)\n",
            "Installing collected packages: graphviz, mxnet-cu101mkl\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101mkl-1.6.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk3qsyRLvPn8"
      },
      "source": [
        "import collections\n",
        "import re\n",
        "import mxnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3JAmD0xvaqS"
      },
      "source": [
        "import os \n",
        "import requests\n",
        "import zipfile\n",
        "import tarfile\n",
        "import hashlib\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZfAQU2kw1Kv"
      },
      "source": [
        "def read_dataset(location):\n",
        "    with open(location) as f:\n",
        "        lines = f.readlines()\n",
        "    return [re.sub('[^A-Za-z]+',' ',line).strip() for line in lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50T-_glH-36Q"
      },
      "source": [
        "lines = read_dataset('wonderland')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_jUbppd4_kho",
        "outputId": "435ecf55-e12b-4808-e50c-93f4b6c6592b"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Alice was beginning to get very tired of sitting by her sister on the'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYUDnWDK_zNd"
      },
      "source": [
        "def tokenize(lines, token = 'word'):\n",
        "    \"\"\" split text lines into word or character tokens\"\"\"\n",
        "    if token =='word':\n",
        "        return [line.split() for line in lines]\n",
        "    elif token == 'char':\n",
        "        return [list(line) for line in lines]\n",
        "    else:\n",
        "        print(f\"ERROR: UNKNOWN TOKEN TYPE :{token}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9LErj8PYrag",
        "outputId": "e4c75525-f35b-41f1-c23c-6342ca0f5a2a"
      },
      "source": [
        "tokens = tokenize(lines)\n",
        "for i in range(5):\n",
        "    print(tokens[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the']\n",
            "['bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the']\n",
            "['book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in']\n",
            "['it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', 'thought', 'Alice', 'without', 'pictures', 'or']\n",
            "['conversations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk4CPYTRrWJ8"
      },
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary for text.\"\"\"\n",
        "    def __init__(self, tokens = None, min_freq = 0, reserved_tokens = None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        \n",
        "        #sorting according to frequency\n",
        "        counter = self.count_corpus(tokens)\n",
        "        self.token_freqs =  sorted(counter.items(), key = lambda x: x[1],reverse = True)\n",
        "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
        "        uniq_tokens += [token for token,freq in self.token_freqs\n",
        "                        if freq>= min_freq and token not in uniq_tokens]\n",
        "        self.idx_to_token , self.token_to_idx = [],dict()\n",
        "        for token in uniq_tokens:\n",
        "            self.idx_to_token.append(token)\n",
        "            self.token_to_idx[token] = len(self.idx_to_token) - 1;\n",
        "\n",
        "    def count_corpus(self,tokens):\n",
        "        \"\"\"Count token freuencies.\"\"\"\n",
        "        if len(tokens)==0 or isinstance(tokens[0],list):\n",
        "            tokens = [token for line in tokens for token in line]\n",
        "        return collections.Counter(tokens)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "    \n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens,(list,tuple)):\n",
        "            return self.token_to_idx.get(tokens,self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list,tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8O9lnPPvjei"
      },
      "source": [
        "vcb = Vocab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7YTsLZ-vqZY",
        "outputId": "501e09c8-8b1e-41cc-df98-9d93516b27a8"
      },
      "source": [
        "vcb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Vocab at 0x7fc396d75c10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyCh6cZgv1rc"
      },
      "source": [
        "vcb = Vocab(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L7bmhcGv-tl",
        "outputId": "200100ac-ebb0-413c-89d5-201e8620d11e"
      },
      "source": [
        "vcb.__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2947"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQpiAjLSwDmE",
        "outputId": "dbef1fad-9c8d-428f-a2dd-59f90aa58eff"
      },
      "source": [
        "print(list(vcb.token_to_idx.items())[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<unk>', 0), ('the', 1), ('and', 2), ('to', 3), ('a', 4), ('I', 5), ('it', 6), ('she', 7), ('of', 8), ('said', 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXnat2IBwspA",
        "outputId": "1d2375bb-908e-422c-a8dc-60a8e5267752"
      },
      "source": [
        "len(vcb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2947"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGw_00TaxL1y",
        "outputId": "f751fa00-5328-43cc-de02-0ee970d0ae55"
      },
      "source": [
        "vcb[tokens[0]] ,tokens[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([10, 12, 268, 3, 104, 29, 497, 8, 370, 82, 16, 408, 20, 1],\n",
              " ['Alice',\n",
              "  'was',\n",
              "  'beginning',\n",
              "  'to',\n",
              "  'get',\n",
              "  'very',\n",
              "  'tired',\n",
              "  'of',\n",
              "  'sitting',\n",
              "  'by',\n",
              "  'her',\n",
              "  'sister',\n",
              "  'on',\n",
              "  'the'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT1lwhFZxVbD"
      },
      "source": [
        "def load_corpus_of_dataset(max_tokens = -1):\n",
        "    \"\"\" It returns token indices and the vocabulary of the time dataset. \"\"\"\n",
        "    lines = read_dataset('wonderland')\n",
        "    tokens = tokenize(lines, 'word')\n",
        "    vocab = Vocab(tokens)\n",
        "\n",
        "    corpus = [vocab[token] for line in tokens for token in line]\n",
        "    if max_tokens>0:\n",
        "        corpus = corpus[:max_tokens]\n",
        "    return corpus, vocab\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOiqrKt-0Zil",
        "outputId": "40257587-9a08-48fc-8dcc-1091278b28b7"
      },
      "source": [
        "corpus , vocab = load_corpus_of_dataset()\n",
        "len(corpus), len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27322, 2947)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryG65i1Pr3dG"
      },
      "source": [
        "import math\n",
        "from mxnet import np,npx \n",
        "npx.set_np()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCbSeq5ar7_s"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESjs7JuI0uA2"
      },
      "source": [
        "class Sequential_data_iter:\n",
        "    \"\"\"Generate a minibatch of subsequences. \"\"\"\n",
        "    def __init__(self,corpus, batch_size, num_steps, randm=False):\n",
        "        self.corpus = corpus\n",
        "        self.batch_size = batch_size\n",
        "        self.num_steps = num_steps\n",
        "        self.num_subseqs = 0\n",
        "        self.num_batches = 0\n",
        "        self.initial_indices= []\n",
        "        \n",
        "    \n",
        "    def random_iter(self):\n",
        "        \"\"\"generate minibatch of subsequence using random sampling.\"\"\"\n",
        "        self.corpus = self.corpus[random.randint(0,self.num_steps-1):]\n",
        "        self.num_subseqs = (len(self.corpus)-1)//self.num_steps\n",
        "        self.initial_indices = list(range(0,self.num_subseqs * self.num_steps, self.num_steps))\n",
        "        random.shuffle(self.initial_indices)\n",
        "\n",
        "        self.num_batches = self.num_subseqs // self.batch_size\n",
        "        for i in range(0, self.batch_size * self.num_batches, self.batch_size):\n",
        "            self.initial_indices_per_batch = self.initial_indices[i: i+self.batch_size]\n",
        "\n",
        "            X = [self.__data(j) for j in self.initial_indices_per_batch]\n",
        "            Y = [self.__data(j+1) for j in self.initial_indices_per_batch]\n",
        "            yield np.array(X), np.array(Y)\n",
        "            \n",
        "\n",
        "\n",
        "    def __data(self,pos):\n",
        "        return self.corpus[pos: pos +self.num_steps]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzPdOECAIqhR"
      },
      "source": [
        "def seq_data_iter_random(corpus, batch_size, num_steps): \n",
        "    \"\"\"Generate a minibatch of subsequences using random sampling.\"\"\"\n",
        "    \n",
        "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
        "    num_subseqs = (len(corpus) - 1) // num_steps\n",
        "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
        "    random.shuffle(initial_indices)\n",
        "    def data(pos):\n",
        "        return corpus[pos: pos + num_steps]\n",
        "    num_batches = num_subseqs // batch_size\n",
        "    for i in range(0, batch_size * num_batches, batch_size):\n",
        "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
        "        X = [data(j) for j in initial_indices_per_batch]\n",
        "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
        "        yield np.array(X), np.array(Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EBJrdFjv0s_"
      },
      "source": [
        "my_seq = list(range(35))\n",
        "data_iter = seq_data_iter_random(my_seq, batch_size = 2, num_steps = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd7Wy5LrwaFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNHaL_-MxHOx",
        "outputId": "de796bef-8cd5-4f43-f020-bd0a46841f77"
      },
      "source": [
        "i = 0\n",
        "for X,Y in (data_iter):\n",
        "    if i>=2:\n",
        "        break\n",
        "    print('X : ',X, '\\nY: ',Y)\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X :  [[14. 15. 16. 17. 18.]\n",
            " [19. 20. 21. 22. 23.]] \n",
            "Y:  [[15. 16. 17. 18. 19.]\n",
            " [20. 21. 22. 23. 24.]]\n",
            "X :  [[29. 30. 31. 32. 33.]\n",
            " [24. 25. 26. 27. 28.]] \n",
            "Y:  [[30. 31. 32. 33. 34.]\n",
            " [25. 26. 27. 28. 29.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLUQ1JDsxg9c"
      },
      "source": [
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
        "    \"\"\"Generate a minibatch of subsequences using sequential partitioning.\"\"\"\n",
        "    # Start with a random offset to partition a sequence\n",
        "    offset = random.randint(0, num_steps)\n",
        "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
        "    Xs = np.array(corpus[offset: offset + num_tokens])\n",
        "    Ys = np.array(corpus[offset + 1: offset + 1 + num_tokens])\n",
        "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
        "    num_batches = Xs.shape[1] // num_steps\n",
        "    for i in range(0, num_steps * num_batches, num_steps):\n",
        "        X = Xs[:, i: i + num_steps]\n",
        "        Y = Ys[:, i: i+ num_steps]\n",
        "        yield X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_yhiDbIbw0",
        "outputId": "ee3ea621-f17b-419b-aa53-14240a128c0c"
      },
      "source": [
        "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
        "    print('X: ', X, '\\nY:', Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  [[ 0.  1.  2.  3.  4.]\n",
            " [17. 18. 19. 20. 21.]] \n",
            "Y: [[ 1.  2.  3.  4.  5.]\n",
            " [18. 19. 20. 21. 22.]]\n",
            "X:  [[ 5.  6.  7.  8.  9.]\n",
            " [22. 23. 24. 25. 26.]] \n",
            "Y: [[ 6.  7.  8.  9. 10.]\n",
            " [23. 24. 25. 26. 27.]]\n",
            "X:  [[10. 11. 12. 13. 14.]\n",
            " [27. 28. 29. 30. 31.]] \n",
            "Y: [[11. 12. 13. 14. 15.]\n",
            " [28. 29. 30. 31. 32.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sSOauzhL1EB"
      },
      "source": [
        "class SeqDataLoader:\n",
        "    \"\"\"An iterator to load sequence data.\"\"\"\n",
        "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
        "        if use_random_iter:\n",
        "            self.data_iter_fn = seq_data_iter_random\n",
        "        else:\n",
        "            self.data_iter_fn = seq_data_iter_sequential\n",
        "        self.corpus, self.vocab = load_corpus_of_dataset(max_tokens)\n",
        "        self.batch_size, self.num_steps = batch_size, num_steps\n",
        "    def __iter__(self):\n",
        "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLcBxf5rMvmo"
      },
      "source": [
        "def load_data(batch_size, num_steps,\n",
        "    use_random_iter=False, max_tokens=10000):\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
        "    data_iter = SeqDataLoader(\n",
        "        batch_size, num_steps, use_random_iter, max_tokens)\n",
        "    return data_iter, data_iter.vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LFuAfyINBgD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6-g8TeXNV11"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RGWlobINXWn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qU0g5HFNkI9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvIipfkDORBa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJW6_INRC5f"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1Dc9o2AR3XS"
      },
      "source": [
        "from mxnet import np, npx\n",
        "from mxnet.gluon import rnn, nn\n",
        "npx.set_np()\n",
        "batch_size, num_steps = 32, 3\n",
        "\n",
        "train_iter, vocab = load_data(batch_size, num_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpgK4cfAWdPe"
      },
      "source": [
        "from mxnet import autograd,gluon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfP9OciqSzpP",
        "outputId": "f5bcd2da-b500-46c3-d795-a2a75793f465"
      },
      "source": [
        "npx.gpu(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gpu(0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76Q3aOcSvem"
      },
      "source": [
        "vocab_size, num_hiddens, device = len(vocab), 256, npx.gpu(0)\n",
        "num_epochs, lr = 500, 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IIyo-1Tk_o"
      },
      "source": [
        "class RNNModel(nn.Block):\n",
        "    \"\"\"The RNN model.\"\"\"\n",
        "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
        "        super(RNNModel, self).__init__(**kwargs)\n",
        "        self.rnn = rnn_layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.dense = nn.Dense(vocab_size)\n",
        "    def forward(self, inputs, state):\n",
        "        X = npx.one_hot(inputs.T, self.vocab_size)\n",
        "        Y, state = self.rnn(X, state)\n",
        "        # The fully-connected layer will first change the shape of `Y` to\n",
        "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\n",
        "        # (`num_steps` * `batch_size`, `vocab_size`).\n",
        "        output = self.dense(Y.reshape(-1, Y.shape[-1]))\n",
        "        return output, state\n",
        "    def begin_state(self, *args, **kwargs):\n",
        "        return self.rnn.begin_state(*args, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2UmeWJOVLks"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8RdDKU6Vytk"
      },
      "source": [
        "class Timer: \n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.start()\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.tik = time.time()\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time.\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time.\"\"\"\n",
        "        return sum(self.times)\n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumulated time.\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iR7VxkaV-4y"
      },
      "source": [
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwjwsYyxW_Ig"
      },
      "source": [
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    if isinstance(net, gluon.Block):\n",
        "        params = [p.data() for p in net.collect_params().values()]\n",
        "    else:\n",
        "        params = net.params\n",
        "    norm = math.sqrt(sum((p.grad ** 2).sum() for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO9_dsI0VLZi"
      },
      "source": [
        "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
        "    \"\"\"Train a model within one epoch (defined in Chapter 8).\"\"\"\n",
        "    state, timer = None, Timer()\n",
        "    metric = Accumulator(2) # Sum of training loss, no. of tokens\n",
        "    for X, Y in train_iter:\n",
        "        if state is None or use_random_iter:\n",
        "            # Initialize `state` when either it is the first iteration or\n",
        "            # using random sampling\n",
        "            state = net.begin_state(batch_size=X.shape[0], ctx=device)\n",
        "        else:\n",
        "            for s in state:\n",
        "                s.detach()\n",
        "        y = Y.T.reshape(-1)\n",
        "        X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n",
        "        with autograd.record():\n",
        "            y_hat, state = net(X, state)\n",
        "            l = loss(y_hat, y).mean()\n",
        "        l.backward()\n",
        "        grad_clipping(net, 1)\n",
        "        updater(batch_size=1) # Since the `mean` function has been invoked\n",
        "        metric.add(l * y.size, y.size)\n",
        "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3_r61w3ZfH4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mxnet import init\n",
        "from IPython import display\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhYazE06ZutG"
      },
      "source": [
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"Set the axes for matplotlib.\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbrjDCumVLNW"
      },
      "source": [
        "class Animator:\n",
        "    \"\"\"For plotting data in animation.\"\"\"\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "                ylim=None, xscale='linear', yscale='linear',\n",
        "                fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
        "                figsize=(5.5, 3.5)):\n",
        "        # Incrementally plot multiple lines\n",
        "        if legend is None:\n",
        "            legend = []\n",
        "        display.set_matplotlib_formats('svg')\n",
        "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1:\n",
        "            self.axes = [self.axes, ]\n",
        "        # Use a lambda function to capture arguments\n",
        "        self.config_axes = lambda: set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "    def add(self, x, y):\n",
        "        # Add multiple data points into the figure\n",
        "        if not hasattr(y, \"__len__\"):\n",
        "            y= [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"):\n",
        "            x = [x] * n\n",
        "        if not self.X:\n",
        "            self.X = [[] for _ in range(n)]\n",
        "        if not self.Y:\n",
        "            self.Y = [[] for _ in range(n)]\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ps7FSDab7W"
      },
      "source": [
        "def sgd(params, lr, batch_size): \n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fctVAmaDaxD6"
      },
      "source": [
        "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
        "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
        "    state = net.begin_state(batch_size=1, ctx=device)\n",
        "    #outputs = [vocab[prefix[0]]]\n",
        "    outputs = [vocab[prefix[0]]]\n",
        "    get_input = lambda: np.reshape(\n",
        "        np.array([outputs[-1]], ctx=device), (1, 1))\n",
        "    for y in prefix[1:]: # Warm-up period\n",
        "        _, state = net(get_input(), state)\n",
        "        outputs.append(vocab[y])\n",
        "    for _ in range(num_preds): # Predict `num_preds` steps\n",
        "        y, state = net(get_input(), state)\n",
        "        \n",
        "        \n",
        "        outputs.append(int(y.argmax(axis=1).reshape(1)))\n",
        "    return ' '.join([vocab.idx_to_token[i] for i in outputs[len(prefix):-1]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4bMojtB9rNC"
      },
      "source": [
        "def sorting(y):\n",
        "    x = sorted(y)\n",
        "    return x[-3:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7MUZG1I-G9x",
        "outputId": "d96fc0cc-d10c-4059-b4aa-87d39e6195d1"
      },
      "source": [
        "sorting([3,2,54,3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 3, 54]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbXsgDd7YDix"
      },
      "source": [
        "def train_ch8(net, train_iter, vocab, lr, num_epochs, device, \n",
        "use_random_iter=False):\n",
        "    \"\"\"Train a model (defined in Chapter 8).\"\"\"\n",
        "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "    animator = Animator(xlabel='epoch', ylabel='perplexity',\n",
        "                            legend=['train'], xlim=[10, num_epochs])\n",
        "    # Initialize\n",
        "    if isinstance(net, gluon.Block):\n",
        "        net.initialize(ctx=device, force_reinit=True,\n",
        "                        init=init.Normal(0.01))\n",
        "        trainer = gluon.Trainer(net.collect_params(),\n",
        "                                'sgd', {'learning_rate': lr})\n",
        "        updater = lambda batch_size: trainer.step(batch_size)\n",
        "    else:\n",
        "        updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
        "    #predict = lambda prefix: predict_ch8(prefix.split(), 3, net, vocab, device)\n",
        "    # Train and predict\n",
        "    for epoch in range(num_epochs):\n",
        "        ppl, speed = train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            animator.add(epoch + 1, [ppl])\n",
        "    print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\n",
        "    #print(predict('I am'))\n",
        "    #print(predict('I gave'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBtjH1mFYEFf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y3XyTudSaB8"
      },
      "source": [
        "#device = npx.cpu()\n",
        "lstm_layer = rnn.LSTM(num_hiddens)\n",
        "model = RNNModel(lstm_layer, len(vocab))\n",
        "train_ch8(model, train_iter, vocab, lr, num_epochs, device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIaIVSIeb5l1"
      },
      "source": [
        "\n",
        "predict = lambda prefix: predict_ch8(prefix.split(), 2, model, vocab, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okLzcfT4hQNG"
      },
      "source": [
        "predict('And')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmL1QhCi1SgC"
      },
      "source": [
        "'ram'.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cs8WwH7hajM"
      },
      "source": [
        "vocab.token_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8Z1SQYoheWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}